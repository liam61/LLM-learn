# 大模型介绍

## Token 介绍

后续文字推测

衡量预测的文字：token

BPE tokenizer（从小到大合并）流程：

1. 给定语料
2. 根据出现频率组合（子词）

单个单词不能作为 token，单个字符也不行

![2](./images/20250615-140705.jpeg)

## Transformer 架构

![2](./images/20250615-140920.jpeg)

1. 编码器
2. 解码器（预测）

自注意机制

![2](./images/20250615-141122.jpeg)

预训练模型

SFT：指令微调

RLHF：基于人类反馈强化学习

![2](./images/20250615-141440.jpeg)

![2](./images/20250615-141540.jpeg)

## CPU vs GPU

![2](./images/20250615-142606.jpeg)

本地部署大模型，通过 localhost 调用
