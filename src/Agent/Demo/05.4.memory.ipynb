{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08139f8",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "1. 内存中短期记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbde3c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import  ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"你好，我是人类！\")\n",
    "memory.chat_memory.add_ai_message(\"你好，我是AI，有什么可以帮助你的吗？\")\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "#实现一个最近的对话窗口，超过窗口条数的对话将被删除\n",
    "memory = ConversationBufferWindowMemory(k=2)\n",
    "\n",
    "memory.save_context({\"input\":\"你好，我是人类!\"},{\"output\":\"你好，我是AI，有什么可以帮助你的吗？\"})\n",
    "memory.save_context({\"input\":\"我想吃鸡肉\"},{\"output\":\"好的，我帮你找找鸡肉的做法\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06a54c5",
   "metadata": {},
   "source": [
    "2. 构建实体清单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e151d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import  OpenAI\n",
    "from langchain.memory import ConversationEntityMemory\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "memory = ConversationEntityMemory(llm=llm)\n",
    "_input = {\n",
    "    \"input\":\"胡八一和王胖子雪莉杨经常在一起冒险，合称盗墓铁三角.\"\n",
    "}\n",
    "memory.load_memory_variables(_input)\n",
    "memory.save_context(\n",
    "    _input,\n",
    "    {\n",
    "        \"output\":\"听起来很刺激，我也想加入他们！\"\n",
    "    }\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({\"input\":\"铁三角是谁?\"})\n",
    "# {'history': 'Human: 胡八一和王胖子雪莉杨经常在一起冒险，合称盗墓铁三角.\\nAI: 听起来很刺激，我也想加入他们！', 'entities': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8355a6e8",
   "metadata": {},
   "source": [
    "3. 使用知识图谱构建记忆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9f65b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import  OpenAI\n",
    "from langchain.memory import ConversationKGMemory\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0\n",
    ")   \n",
    "\n",
    "memory = ConversationKGMemory(llm=llm,return_messages=True)\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "\n",
    "memory.load_memory_variables({\"input\":\"tomie是谁?\"})\n",
    "# {'history': [SystemMessage(content='On tomie: tomie is a training instructor.')]}\n",
    "\n",
    "memory.get_current_entities(\"tomie最喜欢做什么事?\")\n",
    "memory.get_knowledge_triplets(\"tomie最喜欢打游戏\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b0f08d",
   "metadata": {},
   "source": [
    "4. 长对话在内存中的处理方式：总结摘要、token计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ca143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.llms import  OpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "\n",
    "# 缩短了对话空间\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "messages = memory.chat_memory.messages\n",
    "#print(messages)\n",
    "memory.predict_new_summary(messages,\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052c8e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用ChatMessageHistory来快速获得对话摘要\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.llms import  OpenAI\n",
    "\n",
    "hisiory = ChatMessageHistory()\n",
    "hisiory.add_user_message(\"你好，我是人类！\")\n",
    "hisiory.add_ai_message(\"你好，我是AI小丸子，有什么可以帮助你的吗？\")\n",
    "\n",
    "#memory = ConversationSummaryMemory.from_messages(\n",
    "#    llm=OpenAI(temperature=0),\n",
    "#    chat_memory=hisiory,\n",
    "#    return_messages=True\n",
    "#)\n",
    "\n",
    "memory = ConversationSummaryMemory(\n",
    "    llm=OpenAI(temperature=0),\n",
    "    return_messages=True,\n",
    "    buffer=\"\\nThe AI introduces itself as AI Little Maruko and asks if there is anything it can help the human with.\",\n",
    "    chat_memory=hisiory\n",
    ")\n",
    "\n",
    "#memory.buffer\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e2de96",
   "metadata": {},
   "source": [
    "当对话持续进行且对话内容很多的时候\n",
    "可以使用ConversationSummaryBufferMemory来存储对话摘要\n",
    "这是一种非常有用的方式,它会根据token的数量来自动判断是否需要进行摘要\n",
    "当token数量超过阈值的时候,会自动进行摘要\n",
    "在缓冲区中,会保留最近的k条对话\n",
    "比较久的对话会被删除，在删除前会进行摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df75b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=10,\n",
    "    return_messages=True\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "\n",
    "# 会从中间截断\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c8af80",
   "metadata": {},
   "source": [
    "5. Conversation Token Buffer使用token长度来决定什么时候刷新内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be61a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(temperature=0)\n",
    "memory = ConversationTokenBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"不需要资料了，谢谢\"},\n",
    "    {\"output\":\"好的，那我就不打扰你了。\"}\n",
    ")\n",
    "\n",
    "# 取的后面的几句\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fccb6a",
   "metadata": {},
   "source": [
    "## 长时记忆的是实现方式\n",
    "\n",
    "通过向量数据库来存储之前的对话内容，有的向量数据库服务还提供自动摘要等，每次对话的时候，都会从向量数据库里查询最相关的文档或历史对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ebf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.save_context(\n",
    "    {\"input\":\"帮我找一下tomie\"},\n",
    "    {\"output\":\"对不起请问什么是tomie？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"tomie是一个培训讲师\"},\n",
    "    {\"output\":\"好的，我知道了。\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"今天他要讲一门关于RAG的课程\"},\n",
    "    {\"output\":\"好的，我知道了。需要RAG的资料吗？\"}\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\":\"不需要资料了，谢谢\"},\n",
    "    {\"output\":\"好的，那我就不打扰你了。\"}\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_texts(\n",
    "    memory.buffer.split(\"\\n\"),\n",
    "    OpenAIEmbeddings()\n",
    ")\n",
    "FAISS.save_local(vectorstore,\"../assets/test_faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87bfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用\n",
    "FAISS.load_local(\"test_faiss\",OpenAIEmbeddings(model=\"text-embedding-3-small\"),allow_dangerous_deserialization=True).similarity_search(\"tomie是什么职业?\")\n",
    "\n",
    "# [Document(page_content='Human: 今天他要讲一门关于RAG的课程'),\n",
    "#  Document(page_content='AI: 好的，我知道了。需要RAG的资料吗？'),\n",
    "#  Document(page_content='Human: tomie是一个培训讲师'),\n",
    "#  Document(page_content='AI: 好的，那我就不打扰你了。')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新连接本地 memory\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "r1 = FAISS.load_local(\"test_faiss\",OpenAIEmbeddings(),allow_dangerous_deserialization=True)\n",
    "r2 = r1.as_retriever(\n",
    "    search_kwargs={\"k\":1}\n",
    ")\n",
    "memory2 = VectorStoreRetrieverMemory(\n",
    "    retriever=r2\n",
    ")\n",
    "memory2.load_memory_variables({\"prompt\":\"tomie是什么职业?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
