{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636aca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install beautifulsoup4\n",
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d227e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from langchain.agents import AgentExecutor, Tool, initialize_agent\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "\n",
    "# -------------------- 1. RAG知识库构建 --------------------\n",
    "# 加载新加坡气候数据\n",
    "loader = WebBaseLoader([\"https://www.weather.gov.sg/climate-climate-of-singapore/\"])\n",
    "docs = loader.load()\n",
    "\n",
    "# 文档分块处理\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \"]\n",
    ")\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# 初始化带优化的向量数据库\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"singapore-climate\"\n",
    ")\n",
    "\n",
    "# -------------------- 2. 上下文重排序优化 --------------------\n",
    "class OptimizedRetriever:\n",
    "    def __init__(self, base_retriever):\n",
    "        self.retriever = base_retriever\n",
    "        self.reorder = LongContextReorder()\n",
    "        \n",
    "    def get_relevant_documents(self, query):\n",
    "        # 扩大检索范围获取候选文档\n",
    "        raw_docs = self.retriever.get_relevant_documents(query, k=10)\n",
    "        # 应用重排序策略\n",
    "        return self.reorder.transform_documents(raw_docs)[:3]  # 取排序后前三文档\n",
    "\n",
    "base_retriever = vectorstore.as_retriever()\n",
    "optimized_retriever = OptimizedRetriever(base_retriever)\n",
    "\n",
    "# -------------------- 3. 工具系统定义 --------------------\n",
    "# 实时搜索工具\n",
    "search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# 知识库问答工具\n",
    "climate_knowledge = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(temperature=0),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=optimized_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"RealTime_Search\",\n",
    "        func=search_tool.run,\n",
    "        description=\"实时信息检索，适用于天气、新闻等最新动态查询\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Climate_Knowledge\",\n",
    "        func=climate_knowledge.run,\n",
    "        description=\"新加坡气候知识库，包含历史数据和气候特征分析\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# -------------------- 4. Agent初始化 --------------------\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=512\n",
    ")\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=4  # 限制决策步骤防止死循环\n",
    ")\n",
    "\n",
    "# -------------------- 5. 执行示例 --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"今天新加坡的天气如何？与过去五年同期相比有什么显著变化？\"\n",
    "    \n",
    "    response = agent.invoke({\n",
    "        \"input\": query\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"最终答案：\\n{response['output']}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 显示知识库引用来源\n",
    "    if hasattr(climate_knowledge, 'source_documents'):\n",
    "        print(\"\\n引用的知识文档：\")\n",
    "        for doc in climate_knowledge.source_documents:\n",
    "            print(f\"- {doc.metadata['source']} (Page {doc.metadata.get('page', 'N/A')})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
