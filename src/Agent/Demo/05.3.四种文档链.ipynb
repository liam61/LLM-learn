{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae90bf2c",
   "metadata": {},
   "source": [
    "# 4种文档处理链\n",
    "\n",
    "- stuff\n",
    "- refine\n",
    "\n",
    "1. stuffChain\n",
    "\n",
    "最常见文档链，直接将文档塞进 prompt 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import  PyPDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "loader = PyPDFLoader(\"../assets/loader.pdf\")\n",
    "#print(loader.load())\n",
    "\n",
    "prompt_template = \"\"\"对以下文字做简洁的总结:\n",
    "{text}\n",
    "简洁的总结:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    document_variable_name=\"text\",\n",
    ")\n",
    "docs = loader.load()\n",
    "print(stuff_chain.run(docs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab604fde",
   "metadata": {},
   "source": [
    "1.2 封装好的 load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164d69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import  PyPDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "loader = PyPDFLoader(\"../assets/loader.pdf\")\n",
    "docs = loader.load()\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    ")\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True,\n",
    "    )\n",
    "\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0818ac",
   "metadata": {},
   "source": [
    "2. refine\n",
    "\n",
    "通过循环引用 LLM，将文档不断投喂，并产生中间答案，适合逻辑有上下文关联的文档，不适合交叉引用的文档"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d636e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import  PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "#load\n",
    "loader = PyPDFLoader(\"../assets/loader.pdf\")\n",
    "docs = loader.load()\n",
    "#split\n",
    "text_split = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "split_docs = text_split.split_documents(docs)\n",
    "\n",
    "prompt_template = \"\"\"对以下文字做简洁的总结:\n",
    "{text}\n",
    "简洁的总结:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"你的任务是产生最终摘要\\n\"\n",
    "    \"我们已经提供了一个到某个特定点的现有回答:{existing_answer}\\n\"\n",
    "    \"我们有机会通过下面的一些更多上下文来完善现有的回答(仅在需要时使用).\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"根据新的上下文，用中文完善原始回答.\\n\"\n",
    "    \"如果上下文没有用处,返回原始回答.\"\n",
    ")\n",
    "\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt = refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key = \"documents\",\n",
    "    output_key = \"output_text\",\n",
    ")\n",
    "\n",
    "# 执行\n",
    "result = chain({\"documents\":split_docs},return_only_outputs=True)\n",
    "print(result[\"output_text\"])\n",
    "\n",
    "print(\"\\n\\n\".join(result[\"intermediate_steps\"][:3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6968ae7",
   "metadata": {},
   "source": [
    "3. map reduce chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfbbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain\n",
    "from langchain.chains import ReduceDocumentsChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "#load pdf\n",
    "loader = PyPDFLoader(\"../assets/loader.pdf\")\n",
    "docs = loader.load()\n",
    "#split text\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "#print(split_docs)\n",
    "\n",
    "#map chain\n",
    "map_template = \"\"\"对以下文字做简洁的总结:\n",
    "\"{content}\"\n",
    "简洁的总结:\"\"\"\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")\n",
    "map_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=map_prompt,\n",
    ")\n",
    "\n",
    "#reduce chain\n",
    "reduce_template = \"\"\"以下是一个摘要集合:\n",
    "{doc_summaries}\n",
    "将上述摘要与所有关键细节进行总结.\n",
    "总结:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "reduce_chain = LLMChain(\n",
    "    prompt=reduce_prompt,\n",
    "    llm=llm,\n",
    ")\n",
    "stuff_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain,\n",
    "    document_variable_name=\"doc_summaries\",\n",
    ")\n",
    "reduce_final_chain = ReduceDocumentsChain(\n",
    "    combine_documents_chain=stuff_chain,\n",
    "    #超过4000个token就会切入到下一个stuff_chain\n",
    "    collapse_documents_chain=stuff_chain,\n",
    "    token_max=4000,\n",
    ")\n",
    "\n",
    "#map reduce chain\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    document_variable_name=\"content\",\n",
    "    reduce_documents_chain=reduce_final_chain,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b506b8",
   "metadata": {},
   "source": [
    "4. map rerank\n",
    "\n",
    "先将每个文档或文档块投喂给LLM,并对每个文档或文档块生成问题的答案进行打分，然后将打分最高的文档或文档块作为最终答案返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62191ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-16k\")\n",
    "#load\n",
    "loader = PyPDFLoader(\"../assets/loader.pdf\")\n",
    "docs = loader.load()\n",
    "#split\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "chain = load_qa_with_sources_chain(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"map_rerank\", \n",
    "    metadata_keys=['source'], \n",
    "    return_intermediate_steps=True\n",
    "    )\n",
    "\n",
    "\n",
    "query = \"what is this document talk about?answer by chinese\"\n",
    "result = chain({\"input_documents\":split_docs,\"question\":query})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
