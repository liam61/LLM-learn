{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43f4eb7",
   "metadata": {},
   "source": [
    "# ChatDoc:又一个智能文档助手2\n",
    "\n",
    "提高检索精确度\n",
    "\n",
    "8. 使用多重查询提高文档检索精确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e779efea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必须的包\n",
    "from langchain.document_loaders import UnstructuredExcelLoader,Docx2txtLoader,PyPDFLoader\n",
    "from langchain.text_splitter import  CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import  Chroma\n",
    "#引入openai和多重向量检索\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "\n",
    "#定义chatdoc\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.splitText = [] #分割后的文本\n",
    "\n",
    "    # ...\n",
    "    \n",
    "    #提问并找到相关的文本块\n",
    "    def askAndFindFiles(self,question):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        #把问题交给LLM进行多角度的扩展\n",
    "        llm = ChatOpenAI(temperature=0)\n",
    "        retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "            retriever = db.as_retriever(),\n",
    "            llm = llm,\n",
    "        )\n",
    "        return retriever_from_llm.get_relevant_documents(question)\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"example/fake.docx\"\n",
    "chat_doc.splitSentences()\n",
    "#设置下logging查看生成查询\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.DEBUG)\n",
    "unique_doc = chat_doc.askAndFindFiles(\"公司名称是什么?\")\n",
    "print(unique_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8734d02",
   "metadata": {},
   "source": [
    "9. 使用上下文压缩检索降低冗余信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656e7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必须的包\n",
    "from langchain.document_loaders import UnstructuredExcelLoader,Docx2txtLoader,PyPDFLoader\n",
    "from langchain.text_splitter import  CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import  Chroma\n",
    "#引入openai和多重向量检索\n",
    "#from langchain.chat_models import ChatOpenAI\n",
    "#from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "#引入上下文压缩相关包\n",
    "from langchain.llms import  OpenAI\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import  LLMChainExtractor\n",
    "\n",
    "#定义chatdoc\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.splitText = [] #分割后的文本\n",
    "\n",
    "    # ...\n",
    "\n",
    "    #提问并找到相关的文本块\n",
    "    def askAndFindFiles(self,question):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        retriever = db.as_retriever()\n",
    "        llm = OpenAI(temperature=0)\n",
    "        compressor = LLMChainExtractor.from_llm(\n",
    "            llm = llm,\n",
    "        )\n",
    "        compressor_retriever = ContextualCompressionRetriever(\n",
    "            base_retriever = retriever,\n",
    "            base_compressor = compressor,\n",
    "        )\n",
    "        return compressor_retriever.get_relevant_documents(query=question)\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"example/fake.docx\"\n",
    "chat_doc.splitSentences()\n",
    "#设置下logging查看生成查询\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.DEBUG)\n",
    "unique_doc = chat_doc.askAndFindFiles(\"这间公司的负债有多少？\")\n",
    "print(unique_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c04f0a",
   "metadata": {},
   "source": [
    "10. 在向量存储里使用最大边际相似性（MMR）和相似性打分\n",
    "\n",
    "MMR 精确性不够\n",
    "\n",
    "相似性打分：langchain 自己提供了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257b9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必须的包\n",
    "from langchain.document_loaders import UnstructuredExcelLoader,Docx2txtLoader,PyPDFLoader\n",
    "from langchain.text_splitter import  CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import  Chroma\n",
    "\n",
    "\n",
    "#定义chatdoc\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.splitText = [] #分割后的文本\n",
    "\n",
    "    #  ...\n",
    "    \n",
    "    #提问并找到相关的文本块\n",
    "    def askAndFindFiles(self,question):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        # mmr 精度这块不是很好\n",
    "        #retriever = db.as_retriever(search_type=\"mmr\")\n",
    "        retriever = db.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\":.1,\"k\":1})\n",
    "        return retriever.get_relevant_documents(query=question)\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"example/fake.docx\"\n",
    "chat_doc.splitSentences()\n",
    "#设置下logging查看生成查询\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.DEBUG)\n",
    "unique_doc = chat_doc.askAndFindFiles(\"这家公司的地址在哪里?\")\n",
    "print(unique_doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4223f91",
   "metadata": {},
   "source": [
    "## 与文档对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0423bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必须的包\n",
    "from langchain.document_loaders import UnstructuredExcelLoader,Docx2txtLoader,PyPDFLoader\n",
    "from langchain.text_splitter import  CharacterTextSplitter\n",
    "from langchain.embeddings import  OpenAIEmbeddings\n",
    "from langchain.vectorstores import  Chroma\n",
    "#导入聊天所需的模块\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "#定义chatdoc\n",
    "class ChatDoc():\n",
    "    def __init__(self):\n",
    "        self.doc = None\n",
    "        self.splitText = [] #分割后的文本\n",
    "        self.template = [\n",
    "            (\"system\",\"你是一个处理文档的秘书,你从不说自己是一个大模型或者AI助手,你会根据下面提供的上下文内容来继续回答问题.\\n 上下文内容\\n {context} \\n\"),\n",
    "            (\"human\",\"你好！\"),\n",
    "            (\"ai\",\"你好\"),\n",
    "            (\"human\",\"{question}\"),\n",
    "        ]\n",
    "        self.prompt = ChatPromptTemplate.from_messages(self.template)\n",
    "\n",
    "    def getFile(self):\n",
    "        doc = self.doc\n",
    "        loaders = {\n",
    "            \"docx\":Docx2txtLoader,\n",
    "            \"pdf\":PyPDFLoader,\n",
    "            \"xlsx\":UnstructuredExcelLoader,\n",
    "        }\n",
    "        file_extension = doc.split(\".\")[-1]\n",
    "        loader_class = loaders.get(file_extension)\n",
    "        if loader_class:\n",
    "            try:\n",
    "                loader = loader_class(doc)\n",
    "                text = loader.load()\n",
    "                return text\n",
    "            except Exception as e: \n",
    "                print(f\"Error loading {file_extension} files:{e}\") \n",
    "        else:\n",
    "             print(f\"Unsupported file extension: {file_extension}\")\n",
    "             return  None \n",
    "\n",
    "    #处理文档的函数\n",
    "    def splitSentences(self):\n",
    "        full_text = self.getFile() #获取文档内容\n",
    "        if full_text != None:\n",
    "            #对文档进行分割\n",
    "            text_split = CharacterTextSplitter(\n",
    "                chunk_size=150,\n",
    "                chunk_overlap=20,\n",
    "            )\n",
    "            texts = text_split.split_documents(full_text)\n",
    "            self.splitText = texts\n",
    "    \n",
    "    #向量化与向量存储\n",
    "    def embeddingAndVectorDB(self):\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        db =Chroma.from_documents(\n",
    "            documents = self.splitText,\n",
    "            embedding = embeddings,\n",
    "        )\n",
    "        return db\n",
    "    \n",
    "    #提问并找到相关的文本块\n",
    "    def askAndFindFiles(self,question):\n",
    "        db = self.embeddingAndVectorDB()\n",
    "        #retriever = db.as_retriever(search_type=\"mmr\")\n",
    "        retriever = db.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\":.5,\"k\":1})\n",
    "        return retriever.get_relevant_documents(query=question)\n",
    "    \n",
    "    #用自然语言和文档聊天\n",
    "    def chatWithDoc(self,question):\n",
    "        _content = \"\"\n",
    "        context = self.askAndFindFiles(question)\n",
    "        for i in context:\n",
    "            _content += i.page_content\n",
    "        \n",
    "        messages = self.prompt.format_messages(context=_content,question=question)\n",
    "        chat = ChatOpenAI(\n",
    "            model=\"gpt-4\",\n",
    "            temperature=0,\n",
    "        )\n",
    "        return chat.invoke(messages)\n",
    "\n",
    "chat_doc = ChatDoc()\n",
    "chat_doc.doc = \"example/fake.docx\"\n",
    "chat_doc.splitSentences()\n",
    "chat_doc.chatWithDoc(\"公司注册地址是哪里？\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
