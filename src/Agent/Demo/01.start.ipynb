{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5ba7f21",
   "metadata": {},
   "source": [
    "## 安装环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088febf4",
   "metadata": {},
   "source": [
    "\n",
    "1. 安装 pyenv\n",
    "\n",
    "```bash\n",
    "brew install pyenv\n",
    "\n",
    "pyenv install 3.12.10\n",
    "\n",
    "pyenv global 3.12.10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0266dede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaec1d74",
   "metadata": {},
   "source": [
    "2. 安装 Langchain 包\n",
    "\n",
    "```bash\n",
    "pip install langchain\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae4591",
   "metadata": {},
   "source": [
    "3. 安装 openai\n",
    "\n",
    "```bash\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56c3edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.3.23\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /Users/liam.liu/.pyenv/versions/3.12.10/lib/python3.12/site-packages\n",
      "Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n",
      "Required-by: \n",
      "Name: openai\n",
      "Version: 0.28.1\n",
      "Summary: Python client library for the OpenAI API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: OpenAI\n",
      "Author-email: support@openai.com\n",
      "License: \n",
      "Location: /Users/liam.liu/.pyenv/versions/3.12.10/lib/python3.12/site-packages\n",
      "Requires: aiohttp, requests, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show langchain\n",
    "\n",
    "! pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af90d2c",
   "metadata": {},
   "source": [
    "## 运行 openai\n",
    "\n",
    "1. 定义环境变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "089d2dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai_api_key: sk-xxx ; openai_api_key: https://api.deepseek.com\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxx\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://api.deepseek.com\"\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "\n",
    "print(\"openai_api_key:\", openai_api_key, \"; openai_api_key:\", openai_api_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8df02",
   "metadata": {},
   "source": [
    "2. 运行 openai 官方 SDK（Deepseek 举例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548367b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today? 😊\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key, base_url=openai_api_base)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    ],\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "# will print: Hello! How can I assist you today?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962287ae",
   "metadata": {},
   "source": [
    "3. 使用 Langchain 运行 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2812e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我喜欢编程。"
     ]
    }
   ],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "# llm = OpenAI(\n",
    "#     model=\"gpt-4o\",\n",
    "#     openai_api_key=api_key,\n",
    "#     openai_api_base=api_base\n",
    "#     temperature=0,\n",
    "#     )\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    api_key=openai_api_key,\n",
    "    api_base=openai_api_base,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    # max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful translator. Translate the user sentence to Chinese.\"),\n",
    "    (\"human\", \"I love programming.\"),\n",
    "]\n",
    "ai_message = llm.invoke(messages)\n",
    "# AIMessage(content='我喜欢编程。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 20, 'total_tokens': 23, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 20}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': '854c5b87-2b07-49d3-a098-34c463dffbcf', 'finish_reason': 'stop', 'logprobs': None}, id='run-f8e98f70-afb1-43cb-bdb7-b57701b3e757-0', usage_metadata={'input_tokens': 20, 'output_tokens': 3, 'total_tokens': 23, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})\n",
    "\n",
    "# content\n",
    "print(ai_message.content)\n",
    "\n",
    "# stream \n",
    "for chunk in llm.stream(messages):\n",
    "    print(chunk.text(), end=\"\")\n",
    "\n",
    "# async\n",
    "# await llm.ainvoke(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd924274",
   "metadata": {},
   "source": [
    "4. 起名大师"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75567c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师,请模仿示例起3个中国特色的名字,比如男孩经常被叫做狗蛋,女孩经常被叫做翠花\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/dz_bhv6d2dd01px1035pzm2m0000gp/T/ipykernel_74663/685618045.py:17: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'好的！根据中国民间传统，很多接地气的名字会使用朴实的字眼或\"贱名好养活\"的习俗，以下是3组特色名字示例，并附上风格说明：\\n\\n**男孩名**  \\n1. **铁柱** - 钢铁般结实，体现对健康体魄的期盼  \\n2. **二牛** - 排行+牲畜名，寓意像牛一样勤劳能干  \\n3. **栓子** - 旧时认为\"拴住\"孩子能避免夭折，带祈福意味  \\n\\n**女孩名**  \\n1. **招娣** - 反映传统家庭对男孩的期待（谐音\"招弟\"）  \\n2. **小芳** - 六七十年代经典村姑名，充满乡土气息  \\n3. **胖丫** - 用体型特征取名，体现\"胖=有福气\"的观念  \\n\\n**特殊说明**：这类名字常见于20世纪中前期，如今更多作为亲切的昵称或网络调侃使用，实际取名已趋向文雅化。需要其他风格的名字可以告诉我哦！'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    api_key=openai_api_key,\n",
    "    api_base=openai_api_base,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个{county}的名字,比如男孩经常被叫做{boy},女孩经常被叫做{girl}\")\n",
    "message = prompt.format(county=\"中国特色\",boy=\"狗蛋\",girl=\"翠花\")\n",
    "print(message)\n",
    "\n",
    "llm.invoke(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815c3ef",
   "metadata": {},
   "source": [
    "5. 格式化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddde2303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "# 自定义class，继承了 BaseOutputParser\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5039d87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你是一个起名大师,请模仿示例起3个具有美国男孩特色的名字,示例：男孩常用名sam,女孩常用名lucy。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jack,ethan,noah']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\",\n",
    "    api_key=openai_api_key,\n",
    "    api_base=openai_api_base,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    ")\n",
    "prompt = PromptTemplate.from_template(\"你是一个起名大师,请模仿示例起3个具有{county}特色的名字,示例：男孩常用名{boy},女孩常用名{girl}。请返回以逗号分隔的列表形式。仅返回逗号分隔的列表，不要返回其他内容。\")\n",
    "\n",
    "message = prompt.format(county=\"美国男孩\",boy=\"sam\",girl=\"lucy\")\n",
    "print(message)\n",
    "\n",
    "ai_message = llm.invoke(message)\n",
    "CommaSeparatedListOutputParser().parse(ai_message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
